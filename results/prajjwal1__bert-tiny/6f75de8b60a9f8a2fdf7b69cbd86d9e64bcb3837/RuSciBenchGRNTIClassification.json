{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "evaluation_time": 15.129087448120117,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.47",
  "scores": {
    "test": [
      {
        "accuracy": 0.0884765625,
        "f1": 0.07555103897246387,
        "f1_weighted": 0.07556075126326182,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.0884765625,
        "scores_per_experiment": [
          {
            "accuracy": 0.08447265625,
            "f1": 0.07593328750344631,
            "f1_weighted": 0.07593904661208785
          },
          {
            "accuracy": 0.08349609375,
            "f1": 0.06941011606048769,
            "f1_weighted": 0.06948199444803654
          },
          {
            "accuracy": 0.080078125,
            "f1": 0.06848806787820794,
            "f1_weighted": 0.0684392322635203
          },
          {
            "accuracy": 0.0908203125,
            "f1": 0.07507684631739099,
            "f1_weighted": 0.07511338043671018
          },
          {
            "accuracy": 0.0888671875,
            "f1": 0.07253193367767533,
            "f1_weighted": 0.07253072691037224
          },
          {
            "accuracy": 0.1064453125,
            "f1": 0.09576328109677608,
            "f1_weighted": 0.0956875674665445
          },
          {
            "accuracy": 0.09326171875,
            "f1": 0.07911280780111181,
            "f1_weighted": 0.07920143156039254
          },
          {
            "accuracy": 0.0869140625,
            "f1": 0.07040314814187426,
            "f1_weighted": 0.07046257300522106
          },
          {
            "accuracy": 0.0830078125,
            "f1": 0.07496034317819857,
            "f1_weighted": 0.07498845265744569
          },
          {
            "accuracy": 0.08740234375,
            "f1": 0.07383055806946966,
            "f1_weighted": 0.07376310727228745
          }
        ]
      }
    ]
  },
  "task_name": "RuSciBenchGRNTIClassification"
}